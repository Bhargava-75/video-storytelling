<!DOCTYPE html><html><head>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
    <script type="text/javascript" id="MathJax-script" async="" src="js/tex-svg.js">
    </script>
  <meta charset="utf-8">

  <title>StorySynth</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="css/bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet" href="css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">

  <script src="js/jquery.min.js"></script>
  <script src="js/main.js"></script>
  <script defer="" src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><b>StorySynth : Generating Narratives from Pixels</b></h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.csa.iisc.ac.in/~chiru/" target="_blank">Prof.Chiranjib Bhattacharyya</a><sup></sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/bhargava75/" target="_blank">Bhargava Imandi</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/mohit-soni22/" target="_blank">Mohit Soni</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><a href="https://mllab.csa.iisc.ac.in/"><span style="color: rgb(120,120,120); text-decoration: underline;">Machine Learning Lab</span></a>, <a href="https://www.iisc.ac.in/"><span style="color: rgb(120,120,120); text-decoration: underline;">IISc Bangalore</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Bhargava-75/video-storytelling" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              <!-- Demo link -->
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/Bhargava75/video-storytelling" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-rocket"></i>
                  </span>
                  <span>Hugging Face Demo</span>
                </a>
                </span>


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay="" controls="" muted="" loop="" class="small-video">
        <!-- Your video here -->
        <source src="media/Doggie.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Youtube Link : <a href = "https://www.youtube.com/watch?v=YLslsZuEaNE"> https://www.youtube.com/watch?v=YLslsZuEaNE </a>.
      </h2>
        <p class="subtitle"> <b>Story</b> : On a sunny afternoon, two dogs were playing on the green lawn.
          They chased a ball happily, with their tails wagging.
          One dog grabbed the ball while the other barked and tried to take it back.
          They rolled around in the grass, playfully fighting over the ball.
          Tired but happy, they lay down under a tree with the ball between them. 
      </p>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <br>
          <p>
            Explores into the developing fields of video storytelling. This field aims to produce coherent, imaginative, human-like, and clear narratives for videos, especially short ones a relatively unexplored area in current research. Video storytelling brings unique challenges, such as maintaining narrative consistency and handling the complexity of video content. In this work we employed different language models with combined global and local multi-head attention mechanisms to capture frame dependencies at various levels of detail. We tested our experiments on publicly available visual storytelling datasets as well as our own created datasets for video storytelling.          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End paper abstract -->


<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column ">
        <h2 class="title is-3">StoryLLM</h2>
        <div class="content has-text-justified">
          <object data="images/Architecture.png" width="40%" style="display: block; margin: 0 auto;"> </object>
          <br>
          <p>
           Leveraging the power of <b>PGL-SUM</b> architecture has proven instrumental in extracting optimal frames from video sequences.
           By employing this framework, we efficiently identify key frames that encapsulate the essence of the visual content.
           These frames are subsequently processed through a state-of-the-art pipeline combining Vision Transformers (ViT) and GPT-2 models for accurate image captioning.
           Each frame's caption is meticulously generated, culminating in a comprehensive dataset of descriptive elements.
           To synthesize a cohesive narrative from these diverse captions, we explore the capabilities of various Language Models (LLMs) such as <b>BART</b>, <b>T5</b>, and <b>LLama</b>.
           Fine-tuned on a specialized video dataset, these LLMs integrate the individual captions into a coherent and engaging storyline, demonstrating the synergy between advanced machine learning techniques and multimedia content analysis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body has-text-centered">
    <div class="container ">
      <h2 class="title is-3">Qualitative Analysis</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <object data="images/Example1.png" width="100%"> </object>
        </div>
        <div class="item">
        <object data="images/Example2.png" width="100%"> </object>
      </div>
      <div class="item">
        <object data="images/Example3.png" width="100%"> </object>
     </div>
     <div class="item">
      <object data="images/Example4.png" width="100%"> </object>
    </div>
  </div>
</div>
</div>
</section>



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">

            <p>&copy; 2024 Machine Learning Lab , CSA Dept , Indian Institute of Science , Bangalore. All rights reserved.</p>

        </div>
    </div>
  </div>
</footer> 


  
  
</body></html>
